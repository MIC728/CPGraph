"""
LLMä½¿ç”¨è·Ÿè¸ªå™¨ - å…±äº«æ¨¡å—
ä¸º entity_merge.py å’Œ new_test.py æä¾›ç»Ÿä¸€çš„LLMä½¿ç”¨ç»Ÿè®¡åŠŸèƒ½
"""
import os
import functools
import time
import inspect
import json
from typing import Dict, Any, Optional, Callable
from datetime import datetime

class LLMUsageTracker:
    """LLMä½¿ç”¨æƒ…å†µè·Ÿè¸ªå™¨"""

    def __init__(self,
                 count_tokens: bool = True,
                 count_chars: bool = True,
                 track_timing: bool = True,
                 export_to_file: bool = False,
                 export_path: str = "./llm_usage_stats.json"):
        # ç»Ÿè®¡å¼€å…³
        self.count_tokens = count_tokens
        self.count_chars = count_chars
        self.track_timing = track_timing
        self.export_to_file = export_to_file
        self.export_path = export_path

        # ç»Ÿè®¡æ•°æ®ç»“æ„
        self.stats = {
            "session_start": datetime.now().isoformat(),
            "total_calls": 0,
            "total_tokens_input": 0,
            "total_tokens_output": 0,
            "total_chars_input": 0,
            "total_chars_output": 0,
            "total_time": 0.0,
            "calls_by_model": {},
            "calls_by_file": {},
            "calls_by_function": {},
            "errors": [],
            "timeline": []
        }

        # åŸå§‹å‡½æ•°å¼•ç”¨ï¼ˆç”¨äºæ¢å¤ï¼‰
        self._original_func = None
        self._is_installed = False
        self._module_path = "lightrag.llm.openai"
        self._func_name = "openai_complete_if_cache"

    def install(self) -> None:
        """å®‰è£…trackerï¼Œæ›¿æ¢åŸå‡½æ•°"""
        if self._is_installed:
            print("âš  LLM Trackerå·²å®‰è£…ï¼Œè·³è¿‡é‡å¤å®‰è£…")
            return

        try:
            # è·å–æ¨¡å—å’Œå‡½æ•°
            module = __import__(self._module_path, fromlist=[self._func_name])
            original_func = getattr(module, self._func_name)

            # ä¿å­˜åŸå§‹å‡½æ•°
            self._original_func = original_func

            # åˆ›å»ºwrapper
            wrapped_func = self._create_wrapper(original_func)

            # æ›¿æ¢
            setattr(module, self._func_name, wrapped_func)

            self._is_installed = True
            print(f"âœ“ LLM Trackerå·²å®‰è£…")
            print(f"  ç›‘æ§å‡½æ•°: {self._module_path}.{self._func_name}")
            print(f"  Tokenè®¡æ•°: {'âœ“' if self.count_tokens else 'âœ—'}")
            print(f"  å­—ç¬¦è®¡æ•°: {'âœ“' if self.count_chars else 'âœ—'}")
            print(f"  æ—¶é—´è·Ÿè¸ª: {'âœ“' if self.track_timing else 'âœ—'}")

        except Exception as e:
            print(f"âœ— LLM Trackerå®‰è£…å¤±è´¥: {e}")
            raise

    def uninstall(self) -> None:
        """å¸è½½trackerï¼Œæ¢å¤åŸå‡½æ•°"""
        if not self._is_installed:
            print("âš  LLM Trackeræœªå®‰è£…ï¼Œæ— éœ€å¸è½½")
            return

        try:
            # æ¢å¤åŸå‡½æ•°
            module = __import__(self._module_path, fromlist=[self._func_name])
            setattr(module, self._func_name, self._original_func)

            self._is_installed = False
            self._original_func = None
            print("âœ“ LLM Trackerå·²å¸è½½ï¼ŒåŸå‡½æ•°å·²æ¢å¤")

        except Exception as e:
            print(f"âœ— LLM Trackerå¸è½½å¤±è´¥: {e}")
            raise

    def _create_wrapper(self, original_func: Callable) -> Callable:
        """åˆ›å»ºåŒ…è£…å‡½æ•°"""
        @functools.wraps(original_func)
        async def wrapper(*args, **kwargs):
            # æå–è°ƒç”¨ä¿¡æ¯
            start_time = time.time()

            # ä»å‚æ•°ä¸­æå–å…³é”®ä¿¡æ¯
            model = kwargs.get('model', args[0] if args else 'unknown')
            prompt = kwargs.get('prompt', args[1] if len(args) > 1 else '')

            # è·å–è°ƒç”¨è€…ä¿¡æ¯ï¼ˆæ–‡ä»¶ã€å‡½æ•°åã€è¡Œå·ï¼‰
            frame = inspect.currentframe()
            caller_info = self._get_caller_info(frame)

            try:
                # è°ƒç”¨åŸå‡½æ•°
                result = await original_func(*args, **kwargs)

                # è®¡ç®—è€—æ—¶
                elapsed = self.track_timing and (time.time() - start_time) or 0

                # æå–tokenæ•°ï¼ˆå¦‚æœAPIå“åº”ä¸­æœ‰ï¼‰
                tokens_input = 0
                tokens_output = 0
                if self.count_tokens and hasattr(result, 'usage'):
                    tokens_input = getattr(result.usage, 'prompt_tokens', 0)
                    tokens_output = getattr(result.usage, 'completion_tokens', 0)

                # è®°å½•ç»Ÿè®¡
                self._record_usage(
                    model=model,
                    prompt=prompt,
                    response=result,
                    elapsed=elapsed,
                    tokens_input=tokens_input,
                    tokens_output=tokens_output,
                    caller_info=caller_info
                )

                return result

            except Exception as e:
                # è®°å½•é”™è¯¯
                elapsed = self.track_timing and (time.time() - start_time) or 0
                self._record_error(model, str(e), elapsed, caller_info)
                raise

        return wrapper

    def _get_caller_info(self, frame) -> Dict[str, Any]:
        """è·å–è°ƒç”¨è€…ä¿¡æ¯"""
        info = {"file": "unknown", "function": "unknown", "line": 0}

        try:
            # å›æº¯å‡ å±‚æ‰¾åˆ°å®é™…è°ƒç”¨è€…
            for _ in range(5):  # æœ€å¤šå›æº¯5å±‚
                frame = frame.f_back
                if frame is None:
                    break

                filename = frame.f_code.co_filename
                # è·³è¿‡trackerè‡ªèº«çš„è°ƒç”¨
                if "llm_usage_tracker" not in filename and "llm_tracker" not in filename:
                    info["file"] = os.path.basename(filename)
                    info["function"] = frame.f_code.co_name
                    info["line"] = frame.f_lineno
                    break
        finally:
            del frame

        return info

    def _record_usage(self, model: str, prompt: str, response: Any,
                     elapsed: float, tokens_input: int, tokens_output: int,
                     caller_info: Dict[str, Any]) -> None:
        """è®°å½•ä½¿ç”¨ç»Ÿè®¡"""
        # åŸºæœ¬ç»Ÿè®¡
        self.stats["total_calls"] += 1

        if self.count_chars:
            chars_input = len(prompt)
            chars_output = len(str(response))
            self.stats["total_chars_input"] += chars_input
            self.stats["total_chars_output"] += chars_output

        if self.count_tokens:
            self.stats["total_tokens_input"] += tokens_input
            self.stats["total_tokens_output"] += tokens_output

        if self.track_timing:
            self.stats["total_time"] += elapsed

        # æŒ‰æ¨¡å‹ç»Ÿè®¡
        if model not in self.stats["calls_by_model"]:
            self.stats["calls_by_model"][model] = {
                "count": 0, "tokens_input": 0, "tokens_output": 0,
                "chars_input": 0, "chars_output": 0, "time": 0.0
            }

        model_stats = self.stats["calls_by_model"][model]
        model_stats["count"] += 1
        model_stats["tokens_input"] += tokens_input
        model_stats["tokens_output"] += tokens_output
        model_stats["chars_input"] += self.count_chars and len(prompt) or 0
        model_stats["chars_output"] += self.count_chars and len(str(response)) or 0
        model_stats["time"] += elapsed

        # æŒ‰æ–‡ä»¶ç»Ÿè®¡
        file_key = caller_info["file"]
        if file_key not in self.stats["calls_by_file"]:
            self.stats["calls_by_file"][file_key] = {"count": 0, "tokens": 0}
        self.stats["calls_by_file"][file_key]["count"] += 1
        self.stats["calls_by_file"][file_key]["tokens"] += tokens_input + tokens_output

        # æŒ‰å‡½æ•°ç»Ÿè®¡
        func_key = f"{caller_info['function']} ({caller_info['file']}:{caller_info['line']})"
        if func_key not in self.stats["calls_by_function"]:
            self.stats["calls_by_function"][func_key] = {"count": 0, "tokens": 0}
        self.stats["calls_by_function"][func_key]["count"] += 1
        self.stats["calls_by_function"][func_key]["tokens"] += tokens_input + tokens_output

        # æ—¶é—´çº¿è®°å½•
        self.stats["timeline"].append({
            "timestamp": datetime.now().strftime("%H:%M:%S"),
            "model": model,
            "tokens_input": tokens_input,
            "tokens_output": tokens_output,
            "elapsed": elapsed,
            "caller": file_key
        })

        # å¯¼å‡ºåˆ°æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
        if self.export_to_file:
            self._export_stats()

    def _record_error(self, model: str, error: str, elapsed: float, caller_info: Dict) -> None:
        """è®°å½•é”™è¯¯"""
        self.stats["errors"].append({
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "model": model,
            "error": error,
            "elapsed": elapsed,
            "caller": f"{caller_info['file']}:{caller_info['line']}"
        })

    def _export_stats(self) -> None:
        """å¯¼å‡ºç»Ÿè®¡åˆ°æ–‡ä»¶"""
        try:
            with open(self.export_path, 'w', encoding='utf-8') as f:
                json.dump(self.stats, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš  å¯¼å‡ºç»Ÿè®¡å¤±è´¥: {e}")

    def get_report(self, detailed: bool = True) -> str:
        """ç”Ÿæˆä½¿ç”¨æŠ¥å‘Š"""
        report = []
        report.append("=" * 70)
        report.append("LLM API ä½¿ç”¨ç»Ÿè®¡æŠ¥å‘Š")
        report.append("=" * 70)
        report.append(f"ä¼šè¯å¼€å§‹æ—¶é—´: {self.stats['session_start']}")
        report.append(f"æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")

        # æ€»ä½“ç»Ÿè®¡
        report.append("ã€æ€»ä½“ç»Ÿè®¡ã€‘")
        report.append(f"  æ€»è°ƒç”¨æ¬¡æ•°: {self.stats['total_calls']:,}")

        if self.count_tokens:
            total_tokens = self.stats['total_tokens_input'] + self.stats['total_tokens_output']
            report.append(f"  æ€»Tokenæ•°: {total_tokens:,} (è¾“å…¥: {self.stats['total_tokens_input']:,}, è¾“å‡º: {self.stats['total_tokens_output']:,})")

        if self.count_chars:
            total_chars = self.stats['total_chars_input'] + self.stats['total_chars_output']
            report.append(f"  æ€»å­—ç¬¦æ•°: {total_chars:,} (è¾“å…¥: {self.stats['total_chars_input']:,}, è¾“å‡º: {self.stats['total_chars_output']:,})")

        if self.track_timing:
            avg_time = self.stats['total_time'] / max(1, self.stats['total_calls'])
            report.append(f"  æ€»è€—æ—¶: {self.stats['total_time']:.2f}ç§’")
            report.append(f"  å¹³å‡å“åº”æ—¶é—´: {avg_time:.3f}ç§’")

        report.append("")

        # æŒ‰æ¨¡å‹ç»Ÿè®¡
        if self.stats["calls_by_model"]:
            report.append("ã€æŒ‰æ¨¡å‹ç»Ÿè®¡ã€‘")
            for model, stats in self.stats["calls_by_model"].items():
                report.append(f"  ğŸ“Š {model}:")
                report.append(f"     è°ƒç”¨æ¬¡æ•°: {stats['count']}")

                if self.count_tokens:
                    tokens = stats['tokens_input'] + stats['tokens_output']
                    report.append(f"     Tokenæ•°: {tokens:,} (è¾“å…¥: {stats['tokens_input']:,}, è¾“å‡º: {stats['tokens_output']:,})")

                if self.count_chars:
                    chars = stats['chars_input'] + stats['chars_output']
                    report.append(f"     å­—ç¬¦æ•°: {chars:,} (è¾“å…¥: {stats['chars_input']:,}, è¾“å‡º: {stats['chars_output']:,})")

                if self.track_timing:
                    report.append(f"     è€—æ—¶: {stats['time']:.2f}ç§’ ({stats['time']/max(1, stats['count']):.3f}ç§’/æ¬¡)")

                report.append("")

        # æŒ‰æ–‡ä»¶ç»Ÿè®¡
        if self.stats["calls_by_file"] and detailed:
            report.append("ã€æŒ‰æ–‡ä»¶ç»Ÿè®¡ã€‘")
            for file, stats in sorted(self.stats["calls_by_file"].items(),
                                    key=lambda x: x[1]['count'], reverse=True):
                report.append(f"  ğŸ“ {file}: {stats['count']} æ¬¡è°ƒç”¨, {stats['tokens']:,} tokens")
            report.append("")

        # æœ€è¿‘è°ƒç”¨æ—¶é—´çº¿
        if self.stats["timeline"] and detailed:
            report.append("ã€æœ€è¿‘è°ƒç”¨ã€‘")
            for entry in self.stats["timeline"][-10:]:  # æœ€è¿‘10æ¬¡
                report.append(f"  {entry['timestamp']} - {entry['model']} ({entry['caller']})")
                report.append(f"    Tokens: {entry['tokens_input']:,} â†’ {entry['tokens_output']:,}, "
                            f"è€—æ—¶: {entry['elapsed']:.2f}s")
            report.append("")

        # é”™è¯¯ç»Ÿè®¡
        if self.stats["errors"]:
            report.append("ã€é”™è¯¯ç»Ÿè®¡ã€‘")
            report.append(f"  é”™è¯¯æ¬¡æ•°: {len(self.stats['errors'])}")
            for error in self.stats["errors"][-5:]:  # æœ€è¿‘5ä¸ªé”™è¯¯
                report.append(f"  {error['timestamp']} - {error['model']} ({error['caller']})")
                report.append(f"    {error['error'][:100]}...")
            report.append("")

        return "\n".join(report)

    def reset(self) -> None:
        """é‡ç½®ç»Ÿè®¡"""
        self.stats = {
            "session_start": datetime.now().isoformat(),
            "total_calls": 0,
            "total_tokens_input": 0,
            "total_tokens_output": 0,
            "total_chars_input": 0,
            "total_chars_output": 0,
            "total_time": 0.0,
            "calls_by_model": {},
            "calls_by_file": {},
            "calls_by_function": {},
            "errors": [],
            "timeline": []
        }
        print("âœ“ ç»Ÿè®¡å·²é‡ç½®")

    def is_installed(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å·²å®‰è£…"""
        return self._is_installed


# åˆ›å»ºå…¨å±€å®ä¾‹
_tracker = None

def get_tracker():
    """è·å–æˆ–åˆ›å»ºtrackerå®ä¾‹"""
    global _tracker
    if _tracker is None:
        _tracker = LLMUsageTracker(
            count_tokens=True,
            count_chars=True,
            track_timing=True,
            export_to_file=True,  # è‡ªåŠ¨å¯¼å‡ºåˆ°æ–‡ä»¶
            export_path="./llm_usage_stats.json"
        )
    return _tracker

def init_tracker():
    """æ ¹æ®ç¯å¢ƒå˜é‡åˆå§‹åŒ–tracker"""
    # æ£€æŸ¥æ˜¯å¦å¯ç”¨ï¼ˆé»˜è®¤å…³é—­ï¼Œé¿å…å½±å“ç”Ÿäº§ï¼‰
    if os.getenv("ENABLE_LLM_TRACKING", "false").lower() == "true":
        tracker = get_tracker()
        # âš ï¸ é‡è¦ï¼šå¿…é¡»åœ¨å¯¼å…¥ç›®æ ‡å‡½æ•°ä¹‹å‰å®‰è£…Hookï¼Œå¦åˆ™å·²å¯¼å…¥çš„å‡½æ•°å¼•ç”¨ä¸ä¼šè¢«æ›´æ–°
        tracker.install()
        print("âœ“ LLM Tracker å·²å¯ç”¨ (ENABLE_LLM_TRACKING=true)")
        print(f"  ç›‘æ§å‡½æ•°: lightrag.llm.openai.openai_complete_if_cache")
        return True
    else:
        print("â„¹ LLM Tracker æœªå¯ç”¨ (è®¾ç½® ENABLE_LLM_TRACKING=true æ¥å¯ç”¨)")
        return False

def print_report(detailed=True):
    """æ‰“å°ä½¿ç”¨æŠ¥å‘Š"""
    tracker = get_tracker()
    if tracker.is_installed():
        print(tracker.get_report(detailed))
    else:
        print("âš  LLM Tracker æœªå®‰è£…")

def reset_stats():
    """é‡ç½®ç»Ÿè®¡"""
    tracker = get_tracker()
    tracker.reset()

def cleanup():
    """æ¸…ç†ï¼ˆå¯¼å‡ºæ–‡ä»¶ã€å¸è½½ç­‰ï¼‰"""
    tracker = get_tracker()
    if tracker.is_installed():
        print("\n" + "="*70)
        print_report()
        print("="*70 + "\n")
        tracker.uninstall()